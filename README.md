# ğŸš€ AI Assistant for People with Disabilities

## ğŸŒŸ Team Phoenix - Exathon 2025

### ğŸ† Team Members
- **Pankaj Sadhukhan**
- **Saikat Kumar Ghosh**
- **Tuhin Patra**

## ğŸŒ Overview
An **AI-driven accessibility tool** designed to empower individuals with disabilities! Our system integrates cutting-edge AI models to provide **real-time navigation, communication enhancement, hands-free interaction, and mental health assessment.**

## ğŸ”¥ Why This Matters
ğŸ’¡ **Empowering the Visually Impaired**: Navigate the world with confidence using real-time object detection and audio feedback.

ğŸ—£ï¸ **Enhancing Communication for the Hearing & Speech Impaired**: Convert speech to text and vice versa seamlessly.

ğŸ¤– **Hands-Free Interaction for Mobility-Impaired Users**: Control devices effortlessly using intuitive hand gestures.

ğŸ’™ **Mental Health Awareness**: Early detection through AI-driven analysis, ensuring timely support.

## ğŸš€ Key Features
âœ… **Visual Model** â€“ Object detection, depth estimation, and audio feedback for smooth navigation.

âœ… **Speech-to-Text & Text-to-Speech** â€“ Seamless communication with Whisper AI and Tacotron 2.

âœ… **Gesture Recognition** â€“ Control devices hands-free with simple gestures.

âœ… **Mental Health Prediction Model** â€“ AI-powered analysis to detect early mental health concerns.

âœ… **Web Application** â€“ A user-friendly interface integrating all functionalities.

## ğŸ› ï¸ Implementation Details
### ğŸ¯ 1. **Visual Model**
- ğŸ“¸ Captures real-time frames via a camera.
- ğŸ·ï¸ Detects objects using **YOLOv8 segmentation**.
- ğŸ“ Estimates depth with **MiDaS**.
- ğŸ”Š Provides structured audio feedback using **Google Text-to-Speech (gTTS)**.

### ğŸ—£ï¸ 2. **Speech-to-Text & Text-to-Speech**
- ğŸ™ï¸ **Whisper AI** for speech-to-text conversion.
- ğŸ”‰ **Tacotron 2** or **Google TTS** for natural speech synthesis.

### âœ‹ 3. **Gesture Recognition Model**
- ğŸ–ï¸ Uses **Mediapipe Hand Tracking** for intuitive gestures:
  - â˜ï¸ **Index Finger** â†’ Cursor Movement
  - âœŒï¸ **Index + Middle Finger** â†’ Right Click
  - ğŸ¤ **Pinch** â†’ Left Click
  - ğŸ–ï¸ **Open Palm (Up/Down)** â†’ Scroll

### ğŸ§  4. **Mental Health Prediction Model**
- ğŸ“Š Trained on **Wellcome Global Monitor 2020** dataset.
- ğŸ† Best accuracy (**78%**) achieved using **Random Forest + SMOTE**.

### ğŸŒ 5. **Web Application**
- **Backend**: Flask ğŸ
- **Frontend**: HTML, CSS, JavaScript ğŸ¨
- **Features**:
  - ğŸ¯ AI-powered object detection and navigation.
  - ğŸ’¬ Speech & gesture-based interaction.
  - â¤ï¸ Mental health assessment module.


## ğŸ—ï¸ Tech Stack
ğŸ”¹ **Deep Learning**: PyTorch, TensorFlow
ğŸ”¹ **Models**: YOLOv8, MiDaS, Whisper AI, Tacotron 2, Mediapipe
ğŸ”¹ **Web**: Flask, HTML, CSS, JavaScript
ğŸ”¹ **Data Processing**: Pandas, NumPy, OpenCV

## ğŸš€ Future Roadmap
ğŸš€ Improve real-time processing efficiency.
ğŸŒ Expand language support for STT and TTS models.
ğŸ–ï¸ Enhance gesture recognition accuracy.
â¤ï¸ Integrate emotion detection for mental health assessment.


ğŸŒŸ _Let's make the world more accessible for everyone!_
